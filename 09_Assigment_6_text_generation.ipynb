{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtuSrazlNYEL"
      },
      "source": [
        "# Copyright\n",
        "\n",
        "<PRE>\n",
        "Copyright (c) Bálint Gyires-Tóth - All Rights Reserved\n",
        "You may use and modify this code for research and development purpuses.\n",
        "Using this code for educational purposes (self-paced or instructor led) without the permission of the author is prohibited.\n",
        "</PRE>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vriXNd_nL2q6"
      },
      "source": [
        "# Assignment: RNN text generation with your favorite book\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5atve1sMH9n"
      },
      "source": [
        "## 1. Dataset\n",
        "- Download your favorite book from https://www.gutenberg.org/\n",
        "- Split into training (80%) and validation (20%)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-24 02:20:55.485290: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745454055.504097 1185200 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745454055.509858 1185200 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1745454055.525571 1185200 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1745454055.525604 1185200 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1745454055.525607 1185200 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1745454055.525609 1185200 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-04-24 02:20:55.530232: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import re\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvKdt5EyMDug"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of training text: 59916 characters\n",
            "Length of validation text: 14979 characters\n"
          ]
        }
      ],
      "source": [
        "with open('book.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "text = text.replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ').replace('  ', ' ')\n",
        "\n",
        "split_idx = int(len(text) * 0.8)\n",
        "train_text = text[:split_idx]\n",
        "val_text = text[split_idx:]\n",
        "print(f\"Length of training text: {len(train_text)} characters\")\n",
        "print(f\"Length of validation text: {len(val_text)} characters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eQMcyPgMLJ9"
      },
      "source": [
        "## 2. Preprocessing\n",
        "- Convert text to lowercase.  \n",
        "- Remove punctuation (except basic sentence delimiters).  \n",
        "- Tokenize by words or characters (your choice).  \n",
        "- Build a vocabulary (map each unique word to an integer ID)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvXRFVcbMLe9"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z0-9.?! ]+\", \"\", text)\n",
        "    return text\n",
        "\n",
        "train_text = preprocess(train_text)\n",
        "val_text = preprocess(val_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Char-level vocab size: 41\n",
            "xs shape: (58470, 100), ys shape: (58470, 41)\n",
            "val_x shape: (14426, 100), val_y_cat shape: (14426, 41)\n"
          ]
        }
      ],
      "source": [
        "tokenizer = Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts([train_text])\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "max_seq_len = 100\n",
        "def create_char_sequences(text, tokenizer, seq_length):\n",
        "    seq = tokenizer.texts_to_sequences([text])[0]\n",
        "    input_sequences = []\n",
        "    for i in range(seq_length, len(seq)):\n",
        "        input_sequences.append(seq[i-seq_length:i+1])\n",
        "    input_sequences = np.array(input_sequences)\n",
        "    x = input_sequences[:,:-1]\n",
        "    y = input_sequences[:,-1]\n",
        "    y = tf.keras.utils.to_categorical(y, num_classes=vocab_size)\n",
        "    return x, y\n",
        "\n",
        "xs, ys = create_char_sequences(train_text, tokenizer, max_seq_len)\n",
        "val_x, val_y_cat = create_char_sequences(val_text, tokenizer, max_seq_len)\n",
        "print(f'Char-level vocab size: {vocab_size}')\n",
        "print(f'xs shape: {xs.shape}, ys shape: {ys.shape}')\n",
        "print(f'val_x shape: {val_x.shape}, val_y_cat shape: {val_y_cat.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbTZs3OiMMNy"
      },
      "source": [
        "## 3. Embedding Layer in Keras\n",
        "Below is a minimal example of defining an `Embedding` layer:\n",
        "```python\n",
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    input_dim=vocab_size,     # size of the vocabulary\n",
        "    output_dim=128,           # embedding vector dimension\n",
        "    input_length=sequence_length\n",
        ")\n",
        "```\n",
        "- This layer transforms integer-encoded sequences (word IDs) into dense vector embeddings.\n",
        "\n",
        "- Feed these embeddings into your LSTM or GRU OR 1D CNN layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OXCK40l6MRld"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/hsdslab/Documents/Meme_project_TriAn/week9/tf_env/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    input_dim=vocab_size,\n",
        "    output_dim=256,\n",
        "    input_length=max_seq_len,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsXR4RZpMXMi"
      },
      "source": [
        "## 4. Model\n",
        "- Implement an LSTM or GRU or 1D CNN-based language model with:\n",
        "  - **The Embedding layer** as input.\n",
        "  - At least **one recurrent layer** (e.g., `LSTM(256)` or `GRU(256)` or your custom 1D CNN).\n",
        "  - A **Dense** output layer with **softmax** activation for word prediction.\n",
        "- Train for about **5–10 epochs** so it can finish in approximately **2 hours** on a standard machine.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "linweGaUMg0T"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1745454057.657718 1185200 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9770 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "model = Sequential([\n",
        "    embedding_layer,\n",
        "    Bidirectional(LSTM(256, return_sequences=True)),\n",
        "    Dropout(0.3),\n",
        "    Bidirectional(LSTM(256)),\n",
        "    Dropout(0.3),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "optimizer = Adam(learning_rate=0.001, clipnorm=1.0)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggop4h4IMhMT"
      },
      "source": [
        "## 5. Training & Evaluation\n",
        "- **Monitor** the loss on both training and validation sets.\n",
        "- **Perplexity**: a common metric for language models.\n",
        "  - It is the exponent of the average negative log-likelihood.\n",
        "  - If your model outputs cross-entropy loss `H`, then `perplexity = e^H`.\n",
        "  - Try to keep the validation perplexity **under 50** if possible. If you have higher value (which is possible) try to draw conclusions, why doesn't it decrease to a lower value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8d8FS2XMj46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1745454062.749050 1185228 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 99ms/step - accuracy: 0.2058 - loss: 2.8468 - val_accuracy: 0.3266 - val_loss: 2.2859 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 97ms/step - accuracy: 0.3487 - loss: 2.1769 - val_accuracy: 0.3853 - val_loss: 2.0593 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 97ms/step - accuracy: 0.4159 - loss: 1.9492 - val_accuracy: 0.4396 - val_loss: 1.8778 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 97ms/step - accuracy: 0.4682 - loss: 1.7755 - val_accuracy: 0.4840 - val_loss: 1.7627 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 97ms/step - accuracy: 0.5054 - loss: 1.6457 - val_accuracy: 0.4992 - val_loss: 1.7000 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 97ms/step - accuracy: 0.5358 - loss: 1.5369 - val_accuracy: 0.5140 - val_loss: 1.6566 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 98ms/step - accuracy: 0.5565 - loss: 1.4565 - val_accuracy: 0.5200 - val_loss: 1.6420 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5803 - loss: 1.3782\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 98ms/step - accuracy: 0.5803 - loss: 1.3782 - val_accuracy: 0.5234 - val_loss: 1.6431 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 98ms/step - accuracy: 0.6143 - loss: 1.2594 - val_accuracy: 0.5257 - val_loss: 1.6209 - learning_rate: 5.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m228/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6324 - loss: 1.2033\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 97ms/step - accuracy: 0.6324 - loss: 1.2033 - val_accuracy: 0.5261 - val_loss: 1.6426 - learning_rate: 5.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6550 - loss: 1.1236\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 98ms/step - accuracy: 0.6550 - loss: 1.1236 - val_accuracy: 0.5242 - val_loss: 1.6504 - learning_rate: 2.5000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m228/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6690 - loss: 1.0757\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 98ms/step - accuracy: 0.6690 - loss: 1.0757 - val_accuracy: 0.5259 - val_loss: 1.6578 - learning_rate: 1.2500e-04\n"
          ]
        }
      ],
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, min_lr=1e-6, verbose=1)\n",
        "history = model.fit(\n",
        "    xs, ys,\n",
        "    validation_data=(val_x, val_y_cat),\n",
        "    epochs=30,\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    batch_size=256,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.5295 - loss: 1.5853\n",
            "Updated Validation Perplexity: 5.06\n"
          ]
        }
      ],
      "source": [
        "val_loss, val_acc = model.evaluate(val_x, val_y_cat, verbose=1)\n",
        "val_perplexity = math.exp(val_loss)\n",
        "print(f\"Updated Validation Perplexity: {val_perplexity:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbvbBOp3MfTD"
      },
      "source": [
        "## 6. Generation Criteria\n",
        "- After training, generate **two distinct text samples**, each at least **50 tokens**.\n",
        "- Use **different seed phrases** (e.g., “love is” vs. “time will”)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1uHjn6aHMW5K"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Sample 1 ===\n",
            "his death was a story of the man of the story of the story of the story o\n",
            "\n",
            "=== Sample 2 ===\n",
            "her father took who had been so walter that he was a stirit to the story of\n"
          ]
        }
      ],
      "source": [
        "def generate_text(seed_text, next_words=60):\n",
        "    result = seed_text\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([result])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_seq_len - 1, padding='pre')\n",
        "        predicted = model.predict(token_list, verbose=0)\n",
        "        predicted_word_index = np.argmax(predicted, axis=1)[0]\n",
        "        output_word = tokenizer.index_word.get(predicted_word_index, '')\n",
        "        result += '' + output_word\n",
        "    return result\n",
        "\n",
        "print(\"=== Sample 1 ===\")\n",
        "print(generate_text(\"his death was\"))\n",
        "\n",
        "print(\"\\n=== Sample 2 ===\")\n",
        "print(generate_text(\"her father took\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
